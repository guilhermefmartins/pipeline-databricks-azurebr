## ‚öôÔ∏è Orquestra√ß√£o de Pipelines com Databricks e Azure Data Factory (Im√≥veis - Azure Data Lake)
Objetivo
Automatizar a execu√ß√£o de notebooks no Azure Databricks utilizando o Azure Data Factory, com foco em pipelines de dados de im√≥veis organizados nas camadas bronze e silver de um Data Lake na Azure, usando o formato de armazenamento Delta para garantir performance, escalabilidade e versionamento.

# üìå Sum√°rio
- [Contexto](#contexto)
- [Pipeline de Dados](#pipeline-de-dados)
- [Ferramentas Utilizadas](#ferramentas-utilizadas)
- [Orquestra√ß√£o](#orquestra√ß√£o)
- [Como Reproduzir](#como-reproduzir)
- [Resultados e Conclus√µes](#resultados-e-conclus√µes)

Contexto
O projeto teve como foco principal a constru√ß√£o de um pipeline de dados moderno e automatizado, com leitura, transforma√ß√£o e persist√™ncia em Delta Lake, utilizando ferramentas de ponta do ecossistema Azure. Os dados simulam o mercado imobili√°rio e passam por diferentes camadas de tratamento com persist√™ncia eficiente.

# üèó Pipeline de Dados 
Camadas estruturadas no Data Lake:

Bronze: Ingest√£o bruta dos dados originais.

Silver: Dados tratados, limpos e prontos para an√°lise e consumo por dashboards ou modelos de machine learning.

Transforma√ß√µes aplicadas:

Leitura de arquivos originais em CSV/Parquet

Padroniza√ß√£o de nomes e tipos de colunas

Enriquecimento com vari√°veis como faixa de pre√ßo, localiza√ß√£o, tipo de im√≥vel e categoriza√ß√£o de √°reas

Escrita dos dados tratados no formato Delta, garantindo versionamento, transa√ß√µes ACID e performance superior para leitura e atualiza√ß√£o

# üõ† Ferramentas Utilizadas
Azure Databricks: Ambiente baseado em Apache Spark com notebooks em PySpark e Scala, usado para ingest√£o, tratamento e grava√ß√£o dos dados.

Delta Lake: Formato de armazenamento transacional utilizado para garantir consist√™ncia e efici√™ncia nas camadas do Data Lake.

Azure Data Factory (ADF): Interface visual de orquestra√ß√£o para pipelines, controle de execu√ß√£o e integra√ß√£o com servi√ßos da Azure.

Azure Data Lake Storage Gen2: Armazenamento escal√°vel e seguro para os dados, com suporte a hierarquia de diret√≥rios e permiss√µes.

# üîÑ Orquestra√ß√£o
A orquestra√ß√£o foi feita com o Azure Data Factory, utilizando pipelines visuais com agendamentos e monitoramento. As execu√ß√µes foram programadas com triggers baseadas em hor√°rio e configuradas para rodar notebooks espec√≠ficos no Databricks. ADF gerenciou depend√™ncias, falhas e logs, garantindo rastreabilidade e controle no processo.

# üíª Como Reproduzir
Provisionar os servi√ßos:

Azure Databricks

Azure Data Factory

Azure Data Lake Storage Gen2

<br/>
<br/>
<br/>

# Montar o Data Lake no Databricks:

_
configs = {
  "fs.azure.account.auth.type": "OAuth",
  "fs.azure.account.oauth.provider.type": "org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider",
  "fs.azure.account.oauth2.client.id": "<application-id>",
  "fs.azure.account.oauth2.client.secret": dbutils.secrets.get(scope="<scope-name>", key="<key-name>"),
  "fs.azure.account.oauth2.client.endpoint": "https://login.microsoftonline.com/<tenant-id>/oauth2/token"
}

dbutils.fs.mount(
  source = "abfss://<container>@<storage>.dfs.core.windows.net/",
  mountPoint = "/mnt/<nome>",
  extraConfigs = configs
)
_

<br/>
<br/>
<br/>



*Criar pipeline visual no Azure Data Factory:*

Adicionar atividade de execu√ß√£o de notebook

Configurar trigger e fluxo sequencial para bronze ‚Üí silver


üìà Resultados e Conclus√µes
‚úÖ Os dados foram processados com sucesso em um fluxo robusto e automatizado
‚úÖ O uso do formato Delta permitiu maior controle, performance e confiabilidade nas camadas bronze e silver
‚úÖ O Azure Data Factory ofereceu uma interface visual amig√°vel para orquestra√ß√£o, facilitando o agendamento e rastreamento das execu√ß√µes
‚úÖ O projeto demonstrou a integra√ß√£o eficaz entre Databricks e os servi√ßos do Azure, com organiza√ß√£o modular e escal√°vel

üîç Este projeto comprova minha capacidade de desenvolver pipelines completos e escal√°veis em nuvem, combinando engenharia de dados moderna, automa√ß√£o e boas pr√°ticas de orquestra√ß√£o com ferramentas do ecossistema Azure.
